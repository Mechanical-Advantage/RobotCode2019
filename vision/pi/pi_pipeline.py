#!/usr/bin/python3

"""
This program uses a generated GRIP pipeline for object tracking.

It performs calculations on the resulting geometry and publishes the results 
through ZeroMQ for use by the RoboRio.
"""
import cv2
import numpy
import math
from enum import Enum
import time
import zmq
import struct
from collections import namedtuple
from code import interact

# Retro reflective tape pipeline
class GripPipelineRetro:
    """
    An OpenCV pipeline generated by GRIP.
    """
    
    def __init__(self):
        """initializes all values to presets or None if need to be set
        """

        self.__resize_image_width = 160.0
        self.__resize_image_height = 120.0
        self.__resize_image_interpolation = cv2.INTER_LINEAR

        self.resize_image_output = None

        self.__hsv_threshold_input = self.resize_image_output
        self.__hsv_threshold_hue = [71, 86]
        self.__hsv_threshold_saturation = [166, 255.0]
        self.__hsv_threshold_value = [105, 197]

        self.hsv_threshold_output = None

        self.__find_contours_input = self.hsv_threshold_output
        self.__find_contours_external_only = True

        self.find_contours_output = None

        self.__filter_contours_contours = self.find_contours_output
        self.__filter_contours_min_area = 20.0
        self.__filter_contours_min_perimeter = 30.0
        self.__filter_contours_min_width = 0.0
        self.__filter_contours_max_width = 1000.0
        self.__filter_contours_min_height = 0.0
        self.__filter_contours_max_height = 1000.0
        self.__filter_contours_solidity = [79, 100]
        self.__filter_contours_max_vertices = 1000000.0
        self.__filter_contours_min_vertices = 0.0
        self.__filter_contours_min_ratio = 0.0
        self.__filter_contours_max_ratio = 1000.0

        self.filter_contours_output = None

        self.__convex_hulls_contours = self.filter_contours_output

        self.convex_hulls_output = None


    def process(self, source0):
        """
        Runs the pipeline and sets all outputs to new values.
        """
        # Step Resize_Image0:
        #self.__resize_image_input = source0
        #(self.resize_image_output) = self.__resize_image(self.__resize_image_input, self.__resize_image_width, self.__resize_image_height, self.__resize_image_interpolation)

        # Step HSV_Threshold0:
        self.__hsv_threshold_input = source0
        (self.hsv_threshold_output) = self.__hsv_threshold(self.__hsv_threshold_input, self.__hsv_threshold_hue, self.__hsv_threshold_saturation, self.__hsv_threshold_value)

        # Step Find_Contours0:
        self.__find_contours_input = self.hsv_threshold_output
        (self.find_contours_output) = self.__find_contours(self.__find_contours_input, self.__find_contours_external_only)

        # Step Filter_Contours0:
        self.__filter_contours_contours = self.find_contours_output
        (self.filter_contours_output) = self.__filter_contours(self.__filter_contours_contours, self.__filter_contours_min_area, self.__filter_contours_min_perimeter, self.__filter_contours_min_width, self.__filter_contours_max_width, self.__filter_contours_min_height, self.__filter_contours_max_height, self.__filter_contours_solidity, self.__filter_contours_max_vertices, self.__filter_contours_min_vertices, self.__filter_contours_min_ratio, self.__filter_contours_max_ratio)

        # Step Convex_Hulls0:
        self.__convex_hulls_contours = self.filter_contours_output
        (self.convex_hulls_output) = self.__convex_hulls(self.__convex_hulls_contours)


    @staticmethod
    def __resize_image(input, width, height, interpolation):
        """Scales and image to an exact size.
        Args:
            input: A numpy.ndarray.
            Width: The desired width in pixels.
            Height: The desired height in pixels.
            interpolation: Opencv enum for the type fo interpolation.
        Returns:
            A numpy.ndarray of the new size.
        """
        return cv2.resize(input, ((int)(width), (int)(height)), 0, 0, interpolation)

    @staticmethod
    def __hsv_threshold(input, hue, sat, val):
        """Segment an image based on hue, saturation, and value ranges.
        Args:
            input: A BGR numpy.ndarray.
            hue: A list of two numbers the are the min and max hue.
            sat: A list of two numbers the are the min and max saturation.
            lum: A list of two numbers the are the min and max value.
        Returns:
            A black and white numpy.ndarray.
        """
        out = cv2.cvtColor(input, cv2.COLOR_BGR2HSV)
        return cv2.inRange(out, (hue[0], sat[0], val[0]),  (hue[1], sat[1], val[1]))

    @staticmethod
    def __find_contours(input, external_only):
        """Sets the values of pixels in a binary image to their distance to the nearest black pixel.
        Args:
            input: A numpy.ndarray.
            external_only: A boolean. If true only external contours are found.
        Return:
            A list of numpy.ndarray where each one represents a contour.
        """
        if(external_only):
            mode = cv2.RETR_EXTERNAL
        else:
            mode = cv2.RETR_LIST
        method = cv2.CHAIN_APPROX_SIMPLE
        im2, contours, hierarchy =cv2.findContours(input, mode=mode, method=method)
        return contours

    @staticmethod
    def __filter_contours(input_contours, min_area, min_perimeter, min_width, max_width,
                        min_height, max_height, solidity, max_vertex_count, min_vertex_count,
                        min_ratio, max_ratio):
        """Filters out contours that do not meet certain criteria.
        Args:
            input_contours: Contours as a list of numpy.ndarray.
            min_area: The minimum area of a contour that will be kept.
            min_perimeter: The minimum perimeter of a contour that will be kept.
            min_width: Minimum width of a contour.
            max_width: MaxWidth maximum width.
            min_height: Minimum height.
            max_height: Maximimum height.
            solidity: The minimum and maximum solidity of a contour.
            min_vertex_count: Minimum vertex Count of the contours.
            max_vertex_count: Maximum vertex Count.
            min_ratio: Minimum ratio of width to height.
            max_ratio: Maximum ratio of width to height.
        Returns:
            Contours as a list of numpy.ndarray.
        """
        output = []
        for contour in input_contours:
            x,y,w,h = cv2.boundingRect(contour)
            if (w < min_width or w > max_width):
                continue
            if (h < min_height or h > max_height):
                continue
            area = cv2.contourArea(contour)
            if (area < min_area):
                continue
            if (cv2.arcLength(contour, True) < min_perimeter):
                continue
            hull = cv2.convexHull(contour)
            solid = 100 * area / cv2.contourArea(hull)
            if (solid < solidity[0] or solid > solidity[1]):
                continue
            if (len(contour) < min_vertex_count or len(contour) > max_vertex_count):
                continue
            ratio = (float)(w) / h
            if (ratio < min_ratio or ratio > max_ratio):
                continue
            output.append(contour)
        return output

    @staticmethod
    def __convex_hulls(input_contours):
        """Computes the convex hulls of contours.
        Args:
            input_contours: A list of numpy.ndarray that each represent a contour.
        Returns:
            A list of numpy.ndarray that each represent a contour.
        """
        output = []
        for contour in input_contours:
            output.append(cv2.convexHull(contour))
        return output

class GripPipelineHatch:
    """
    An OpenCV pipeline generated by GRIP.
    """
    
    def __init__(self):
        """initializes all values to presets or None if need to be set
        """

        self.__resize_image_width = 160.0
        self.__resize_image_height = 120.0
        self.__resize_image_interpolation = cv2.INTER_CUBIC

        self.resize_image_output = None

        self.__blur_input = self.resize_image_output
        self.__blur_type = BlurType.Box_Blur
        self.__blur_radius = 1.4414422146908874

        self.blur_output = None

        self.__hsv_threshold_input = self.blur_output
        self.__hsv_threshold_hue = [22.66187050359711, 40.546076257074276]
        self.__hsv_threshold_saturation = [29.352516236065103, 156.65527184261805]
        self.__hsv_threshold_value = [150.43164789676666, 255.0]

        self.hsv_threshold_output = None

        self.__find_contours_input = self.hsv_threshold_output
        self.__find_contours_external_only = True

        self.find_contours_output = None

        self.__convex_hulls_contours = self.find_contours_output

        self.convex_hulls_output = None

        self.__filter_contours_contours = self.convex_hulls_output
        self.__filter_contours_min_area = 150.0
        self.__filter_contours_min_perimeter = 0.0
        self.__filter_contours_min_width = 0.0
        self.__filter_contours_max_width = 1000.0
        self.__filter_contours_min_height = 0.0
        self.__filter_contours_max_height = 1000.0
        self.__filter_contours_solidity = [0.0, 100.0]
        self.__filter_contours_max_vertices = 1000000.0
        self.__filter_contours_min_vertices = 12.0
        self.__filter_contours_min_ratio = 0.0
        self.__filter_contours_max_ratio = 1000.0

        self.filter_contours_output = None


    def process(self, source0):
        """
        Runs the pipeline and sets all outputs to new values.
        """
        # Step Resize_Image0:
        self.__resize_image_input = source0
        (self.resize_image_output) = self.__resize_image(self.__resize_image_input, self.__resize_image_width, self.__resize_image_height, self.__resize_image_interpolation)

        # Step Blur0:
        self.__blur_input = self.resize_image_output
        (self.blur_output) = self.__blur(self.__blur_input, self.__blur_type, self.__blur_radius)

        # Step HSV_Threshold0:
        self.__hsv_threshold_input = self.blur_output
        (self.hsv_threshold_output) = self.__hsv_threshold(self.__hsv_threshold_input, self.__hsv_threshold_hue, self.__hsv_threshold_saturation, self.__hsv_threshold_value)

        # Step Find_Contours0:
        self.__find_contours_input = self.hsv_threshold_output
        (self.find_contours_output) = self.__find_contours(self.__find_contours_input, self.__find_contours_external_only)

        # Step Convex_Hulls0:
        self.__convex_hulls_contours = self.find_contours_output
        (self.convex_hulls_output) = self.__convex_hulls(self.__convex_hulls_contours)

        # Step Filter_Contours0:
        self.__filter_contours_contours = self.convex_hulls_output
        (self.filter_contours_output) = self.__filter_contours(self.__filter_contours_contours, self.__filter_contours_min_area, self.__filter_contours_min_perimeter, self.__filter_contours_min_width, self.__filter_contours_max_width, self.__filter_contours_min_height, self.__filter_contours_max_height, self.__filter_contours_solidity, self.__filter_contours_max_vertices, self.__filter_contours_min_vertices, self.__filter_contours_min_ratio, self.__filter_contours_max_ratio)


    @staticmethod
    def __resize_image(input, width, height, interpolation):
        """Scales and image to an exact size.
        Args:
            input: A numpy.ndarray.
            Width: The desired width in pixels.
            Height: The desired height in pixels.
            interpolation: Opencv enum for the type fo interpolation.
        Returns:
            A numpy.ndarray of the new size.
        """
        return cv2.resize(input, ((int)(width), (int)(height)), 0, 0, interpolation)

    @staticmethod
    def __blur(src, type, radius):
        """Softens an image using one of several filters.
        Args:
            src: The source mat (numpy.ndarray).
            type: The blurType to perform represented as an int.
            radius: The radius for the blur as a float.
        Returns:
            A numpy.ndarray that has been blurred.
        """
        if(type is BlurType.Box_Blur):
            ksize = int(2 * round(radius) + 1)
            return cv2.blur(src, (ksize, ksize))
        elif(type is BlurType.Gaussian_Blur):
            ksize = int(6 * round(radius) + 1)
            return cv2.GaussianBlur(src, (ksize, ksize), round(radius))
        elif(type is BlurType.Median_Filter):
            ksize = int(2 * round(radius) + 1)
            return cv2.medianBlur(src, ksize)
        else:
            return cv2.bilateralFilter(src, -1, round(radius), round(radius))

    @staticmethod
    def __hsv_threshold(input, hue, sat, val):
        """Segment an image based on hue, saturation, and value ranges.
        Args:
            input: A BGR numpy.ndarray.
            hue: A list of two numbers the are the min and max hue.
            sat: A list of two numbers the are the min and max saturation.
            lum: A list of two numbers the are the min and max value.
        Returns:
            A black and white numpy.ndarray.
        """
        out = cv2.cvtColor(input, cv2.COLOR_BGR2HSV)
        return cv2.inRange(out, (hue[0], sat[0], val[0]),  (hue[1], sat[1], val[1]))

    @staticmethod
    def __find_contours(input, external_only):
        """Sets the values of pixels in a binary image to their distance to the nearest black pixel.
        Args:
            input: A numpy.ndarray.
            external_only: A boolean. If true only external contours are found.
        Return:
            A list of numpy.ndarray where each one represents a contour.
        """
        if(external_only):
            mode = cv2.RETR_EXTERNAL
        else:
            mode = cv2.RETR_LIST
        method = cv2.CHAIN_APPROX_SIMPLE
        im2, contours, hierarchy =cv2.findContours(input, mode=mode, method=method)
        return contours

    @staticmethod
    def __convex_hulls(input_contours):
        """Computes the convex hulls of contours.
        Args:
            input_contours: A list of numpy.ndarray that each represent a contour.
        Returns:
            A list of numpy.ndarray that each represent a contour.
        """
        output = []
        for contour in input_contours:
            output.append(cv2.convexHull(contour))
        return output

    @staticmethod
    def __filter_contours(input_contours, min_area, min_perimeter, min_width, max_width,
                        min_height, max_height, solidity, max_vertex_count, min_vertex_count,
                        min_ratio, max_ratio):
        """Filters out contours that do not meet certain criteria.
        Args:
            input_contours: Contours as a list of numpy.ndarray.
            min_area: The minimum area of a contour that will be kept.
            min_perimeter: The minimum perimeter of a contour that will be kept.
            min_width: Minimum width of a contour.
            max_width: MaxWidth maximum width.
            min_height: Minimum height.
            max_height: Maximimum height.
            solidity: The minimum and maximum solidity of a contour.
            min_vertex_count: Minimum vertex Count of the contours.
            max_vertex_count: Maximum vertex Count.
            min_ratio: Minimum ratio of width to height.
            max_ratio: Maximum ratio of width to height.
        Returns:
            Contours as a list of numpy.ndarray.
        """
        output = []
        for contour in input_contours:
            x,y,w,h = cv2.boundingRect(contour)
            if (w < min_width or w > max_width):
                continue
            if (h < min_height or h > max_height):
                continue
            area = cv2.contourArea(contour)
            if (area < min_area):
                continue
            if (cv2.arcLength(contour, True) < min_perimeter):
                continue
            hull = cv2.convexHull(contour)
            solid = 100 * area / cv2.contourArea(hull)
            if (solid < solidity[0] or solid > solidity[1]):
                continue
            if (len(contour) < min_vertex_count or len(contour) > max_vertex_count):
                continue
            ratio = (float)(w) / h
            if (ratio < min_ratio or ratio > max_ratio):
                continue
            output.append(contour)
        return output


BlurType = Enum('BlurType', 'Box_Blur Gaussian_Blur Median_Filter Bilateral_Filter')


def extra_processing_delivery(pipeline, zmq_pub):
    """
    Performs extra processing on the pipeline's outputs and publishes data
    :param pipeline: the pipeline that just processed an image
    :return: None
    """
    # Camera constants
    horiz_FOV = 25.18 * 2 # ELP 57.64, LifeCam 25.18 * 2, XBox 41.97
    vert_FOV = 52.696 # ELP 42.36, LifeCam 52.696, XBox 32.67
    height = 33.5
    vert_angle = 12 # How far down the camera is pointed
    horiz_angle = 0 # How far to the right the camera is pointed
    horiz_offset = 0 # How far to the right the camera is shifted
    width_pixels = 320
    height_pixels = 240

    # Target constants
    target_bottom_height = 26.17519
    target_farthest_corner_height = 26.67595 # Height from ground to farthest left/right corners
    target_half_width = 7.355315 # Distance from center of pair to edge of target

    # Calculated constants
    half_height_pixels = height_pixels / 2
    half_width_pixels = width_pixels / 2
    horiz_tan = math.tan(math.radians(horiz_FOV/2))
    vert_tan = math.tan(math.radians(vert_FOV/2))
    target_half_width_squared = target_half_width**2
    target_width = target_half_width*2
    target_width_squared = target_width**2

    def tilted_left(box):
        return box[0][1] < box[3][1] # 1st point y above 4th point y
    def tilted_right(box):
        return box[3][1] < box[0][1] # 4th point y above 1st point y
    def find_center(box1, box2):
        """
        Take a (corner coords, arearect) and return (x, y)
        """
        return (((box2[1][0][0]+box2[1][1][0]/2)+(box1[1][0][0]+box1[1][1][0]/2))/2, \
        ((box2[1][0][1]+box2[1][1][1]/2)+(box1[1][0][1]+box1[1][1][1]/2))/2)
    def calc_angle_h(pixel_x, distance):
        """
        Calculate angle to pixel x coordinate. Distance to point required in case horiz_offset != 0.
        """
        angle_h =  (math.degrees(
                math.atan(((pixel_x-half_width_pixels)*horiz_tan
                /half_width_pixels)))) - horiz_angle
        if horiz_offset != 0:
            horiz_distance = math.tan(math.radians(angle_h_robot)) * distance
            horiz_distance += horiz_offset
            angle_h = math.degrees(math.atan(horiz_distance/distance))
        return angle_h
    def calc_distance(pixel_y, point_height=target_bottom_height):
        """
        Calculate distance and angle v. Returns (distance, angle_v)
        """
        angle_v = (math.degrees(
                math.atan(((pixel_y-half_height_pixels)*-1*vert_tan
                /half_height_pixels)))) - vert_angle
        distance = abs(point_height-height) / math.tan(math.radians(abs(angle_v)))
        return (distance, angle_v)

    VisionTarget = namedtuple("VisionTarget", ["left_box", "right_box", "center"])

    boxes = [cv2.minAreaRect(contour) for contour in pipeline.convex_hulls_output]
    # minAreaRect returns ((x, y), (width, height), angle), angle is -90 to 0
    # see https://stackoverflow.com/questions/15956124/minarearect-angles-unsure-about-the-angle-returned
    boxes = [[cv2.boxPoints(box), box] for box in boxes] # Create (corner coords, arearect) tuples

    boxes.sort(key=lambda box: box[1][0][0]) # Sort by x position
    targets = []
    # Iterate over pairs of boxes (saving to VisionTargets) and find centers
    for first, second in zip(boxes[::2], boxes[1::2]):
        targets.append(VisionTarget(first, second, center = \
        find_center(first, second)))
    # Other set of combinations
    # Not all combinations will be valid, that is expected
    for first, second in zip(boxes[1::2], boxes[2::2]):
        targets.append(VisionTarget(first, second, center = \
        find_center(first, second)))
    # Sort coordinates within each box by their x position
    for target in targets:
        target.left_box[0] = sorted(target.left_box[0], key=lambda point: point[0])
        target.right_box[0] = sorted(target.right_box[0], key=lambda point: point[0])
    # Filter out target possibilities without correct tilts
    targets = list(filter(lambda target: tilted_right(target.left_box[0]) and \
    tilted_left(target.right_box[0]), targets))
    # Find target with lowest y value (closest to camera)
    # targets.sort(key=lambda target: target.center[1], reverse=True)
    # Pick target closest to center of frame (x), may need to use angle_h if off center camera
    targets.sort(key = lambda target: abs(target.center[0]-half_width_pixels))
    print([abs(target.center[0]-half_width_pixels) for target in targets])
    try:
        target = targets[0]
    except IndexError:
        print("No valid targets found")
        return

    # Average the y of the lowest in frame (max y) corner coords
    # max returns (x,y) so get [1]
    lower_center_y = (max(target.left_box[0], key=lambda point: point[1])[1] + \
    max(target.right_box[0], key=lambda point: point[1])[1])/2

    distance, angle_v = calc_distance(lower_center_y)
    angle_h_robot = calc_angle_h(target.center[0], distance)
    print("Angle V:", angle_v)
    print("Distance:", distance)
    print("Angle:", angle_h_robot)
    # Find target angle from robot perspective to each edge of the pair
    distance_right_edge = calc_distance(target.right_box[0][3][1], \
    target_farthest_corner_height)[0]
    distance_left_edge = calc_distance(target.left_box[0][0][1], \
    target_farthest_corner_height)[0]
    print("Y L:", target.left_box[0][0][1])
    print("Y R:", target.right_box[0][3][1])
    print("Distance L:", distance_left_edge)
    print("Distance R:", distance_right_edge)
    # Law of cosines: https://www.mathsisfun.com/algebra/trig-cosine-law.html
    # Trying to find B here using cos(B) = (c^2+a^2-b^2)/2ca
    # Where b is distance_right_edge, a is target_center_to_edge, c is distance_left_edge
    target_angle_left_cos = (distance_left_edge**2 + target_width_squared - distance_right_edge**2) / \
    (2*distance_left_edge*target_width)
    # Swap which is b and c to find angle to right corner
    target_angle_right_cos = (distance_right_edge**2 + target_width_squared - distance_left_edge**2) / \
    (2*distance_right_edge*target_width)
    # Angle directly to center from left edge
    target_angle_cos = (distance**2 + target_half_width_squared - distance_left_edge**2) / \
    (2*distance*target_half_width)
    # interact(local=locals())
    target_angle = math.acos(target_angle_cos)
    target_angle_left = math.acos(target_angle_left_cos)
    target_angle_right = math.acos(target_angle_right_cos)
    print("Target Angle:", math.degrees(target_angle))
    print("Target Angle L:", math.degrees(target_angle_left))
    print("Target Angle R:", math.degrees(target_angle_right))
    zmq_pub.zmqPubDoubles("distangle", 0.0, distance, angle_h_robot, target_angle)


def extra_processing_hatch(pipeline, zmq_pub):
    # Camera constants
    horiz_FOV = 25.18 * 2
    vert_FOV = 52.696
    height = 31
    vert_angle = 52 # How far down the camera is pointed
    horiz_angle = 0 # How far to the right the camera is pointed
    horiz_offset = 0 # How far to the right the camera is shifted
    width_pixels = 160
    height_pixels = 120

    # Calculated constants
    half_height_pixels = height_pixels / 2
    half_width_pixels = width_pixels / 2
    horiz_tan = math.tan(math.radians(horiz_FOV/2))
    vert_tan = math.tan(math.radians(vert_FOV/2))

    contours = pipeline.filter_contours_output
    contours.sort(key=cv2.contourArea) # Find largest area contour
    try:
        x, y, w, h = cv2.boundingRect(contours[0])
        center = ((x+(w/2)), (y+(h/2)));

        angle_h = (math.degrees(
                    math.atan(((center[0]-half_width_pixels)*horiz_tan
                    /half_width_pixels)))) - horiz_angle
        angle_v = (math.degrees(
                    math.atan(((center[1]-half_height_pixels)*-1*vert_tan
                    /half_height_pixels)))) - vert_angle
        distance = math.tan(math.radians(90-abs(angle_v))) * height
        if horiz_offset != 0:
            horiz_distance = math.tan(math.radians(angle_h)) * distance
            horiz_distance += horiz_offset
            angle_h = math.degrees(math.atan(horiz_distance/distance))
        zmq_pub.zmqPubDoubles("distangle", 0.0, distance, angle_h)
        print("Distance:", distance)
        print("Angle:", angle_h)
    except IndexError:
        # No contours found
        print("Ran pipeline but no contours")


def getTimeMS():
    return int(round(time.time() * 1000))

class ZmqPubIF:
    """
    A simple zmq wrapper class that provides publishing functionality
    """
    def __init__(self, port):
        self.socket = context.socket(zmq.PUB)
        self.socket.bind("tcp://*:%s" % port)

    def zmqPubStr(self, topic, dataStr):
        # The topic is the first string sent
        self.socket.send_string(topic, zmq.SNDMORE)
        # Here we're assuming we're just sending a string as payload
        self.socket.send_string(dataStr)

    def zmqPubDoubles(self, topic, *doubles):
        self.socket.send_string(topic, zmq.SNDMORE)
        for double in doubles[:-1]:
            self.socket.send(struct.pack("!d", double), zmq.SNDMORE)
        self.socket.send(struct.pack("!d", doubles[-1]))

class ZmqRecvIF:
    """
    A simple class to recieve commands over ZeroMQ
    """
    def __init__(self, port):
        self.socket = context.socket(zmq.PULL)
        self.socket.bind("tcp://*:%s" % port)
        self.flags = 0

    def recv_command(self):
        return self.socket.recv_multipart(self.flags)

    def set_blocking(self, block):
        self.flags = 0 if block else zmq.NOBLOCK


context = zmq.Context()
def main():
    zmq_publish_port = "5556"
    zmq_recv_port = "5555"
    Pipeline = namedtuple("Pipeline", ["GRIP_pipeline", "processing_func", \
    "camera"])

    print('Initializing ZMQ Publisher')
    zmq_pub = ZmqPubIF(zmq_publish_port)

    print('Initializing ZMQ Reciever')
    zmq_recv = ZmqRecvIF(zmq_recv_port)

    print('Creating pipelines')
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
    # cap.set(cv2.CAP_PROP_BRIGHTNESS, 0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)
    cap.set(cv2.CAP_PROP_FPS, 30)
    cap.set(cv2.CAP_PROP_AUTO_EXPOSURE, 0.25) # Disable auto exposure
    cap.set(cv2.CAP_PROP_EXPOSURE, 0) # Minimum exposure, should be 0 on LifeCam/XBox and 0.003 on new ELP
    # cap.set(cv2.CAP_PROP_SHARPNESS, 0) # Removes haloing on ELP, not needed on LifeCam or XBox
    pipelines = {b"none" : None, \
    b"delivery" : Pipeline(GripPipelineRetro(), \
    extra_processing_delivery, cap),
    b"hatch" : Pipeline(GripPipelineHatch(), \
    extra_processing_hatch, cap)}
    pipeline = None

    print('Running pipeline')
    while cap.isOpened():
        try:
            zmq_command = zmq_recv.recv_command()
            print("Recieved command", zmq_command[0])
            if zmq_command[0] == b"set_pipeline":
                print("Set pipeline to {}".format(zmq_command[1].decode()))
                pipeline = pipelines[zmq_command[1]]
                if pipeline is not None:
                    zmq_recv.set_blocking(False)
                    pipeline.camera.grab() # Flush the 1 frame that could be in the buffer
                else:
                    zmq_recv.set_blocking(True) # Block while waiting for commands when not running a pipeline
        except zmq.ZMQError:
            # No command
            pass
        if pipeline is not None:
            have_frame, frame = pipeline.camera.read()
            if have_frame:
                pipeline.GRIP_pipeline.process(frame)
                pipeline.processing_func(pipeline.GRIP_pipeline, zmq_pub)

    print('Capture closed')


if __name__ == '__main__':
    main()
